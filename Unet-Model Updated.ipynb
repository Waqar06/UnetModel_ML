{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_slicer \n",
    "import cv2 as cv\n",
    "from numpy import array\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import sys, shutil\n",
    "import os, os.path\n",
    "import keras\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ReLU\n",
    "from tensorflow.keras.layers import Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Reshape\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import asarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_folds = 5\n",
    "class_names = ['No0','Yes1']\n",
    "class_names1 = ['lowerNo0' , 'lowerYes1'] #// folder name\n",
    "class_names2 = ['upperNo0' , 'upperYes1']\n",
    "x_train=[]\n",
    "x_train1=[]\n",
    "y_train=[]\n",
    "y_train1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_data(folder='C:/Users/Waqar/Desktop/zeeshan/DELL PC/DELL PC/One/Original'):\n",
    "    c = 0\n",
    "    for i in range(2):\n",
    "        file_name = glob.glob(folder +'/'+str(class_names[i])+'/*')\n",
    "        names=[]\n",
    "        for path in file_name:\n",
    "            foldername=os.path.basename(path)\n",
    "            names.append(foldername)\n",
    "        Original_Folder_Image_count = len(names)\n",
    "        for j in range(Original_Folder_Image_count):  \n",
    "            path = folder + \"/\" + str(class_names[i]) + \"/\" + str(names[j]) \n",
    "            #img=cv.imread(path,cv.IMREAD_GRAYSCALE)\n",
    "            img = Image.open(path)\n",
    "            gray_image = ImageOps.grayscale(img)\n",
    "            PATH = glob.glob(path)\n",
    "            for img in PATH:\n",
    "                image_array=[]\n",
    "                result = image_slicer.slice(img, 4)\n",
    "                for res in result:\n",
    "                    image_array.append(res.image)\n",
    "                with Image.open(path) as im:\n",
    "                    x, y = im.size\n",
    "                totalsize = x*y\n",
    "                if totalsize == 16384:\n",
    "                    os.remove(path)\n",
    "                a = np.array(image_array[0])\n",
    "                b = np.array(image_array[1])\n",
    "                c = np.array(image_array[2])\n",
    "                d = np.array(image_array[3])\n",
    "                #x = np.concatenate((a, b[...,None]), axis=2).shape\n",
    "                x = np.stack((a,b), axis=2)\n",
    "                y = np.stack((c,d), axis=2)\n",
    "                x_train.append(x)\n",
    "                x_train1.append(y)\n",
    "    files= []\n",
    "    path_to_your_files = r'C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Original\\No0'\n",
    "    copy_to_path = r'C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Lowers\\lowerNo0'\n",
    "    copy_to_path1 = r'C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Uppers\\upperNo0'\n",
    "    path_to_your_files1 = r'C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Original\\No0'\n",
    "\n",
    "    files_list = sorted(os.listdir(path_to_your_files))\n",
    "    orders = range(3, len(files_list) ,4)\n",
    "    orders1 = range(2, len(files_list) ,4)\n",
    "\n",
    "    for order in orders:\n",
    "        files = files_list[order] \n",
    "        shutil.move(os.path.join(path_to_your_files, files), os.path.join(copy_to_path, files))\n",
    "\n",
    "    for a in orders1:\n",
    "        files = files_list[a] \n",
    "        shutil.move(os.path.join(path_to_your_files, files), os.path.join(copy_to_path, files)) \n",
    " \n",
    "    files_list = sorted(os.listdir(path_to_your_files))\n",
    "    for f in range(Original_Folder_Image_count*2):\n",
    "        files = files_list[f]\n",
    "        shutil.move(os.path.join(path_to_your_files1, files), os.path.join(copy_to_path1, files)) \n",
    "\n",
    "    files= []\n",
    "    path_to_your_files = r'C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Original\\Yes1'\n",
    "    copy_to_path = r'C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Lowers\\lowerYes1'\n",
    "    copy_to_path1 = r'C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Uppers\\upperYes1'\n",
    "    path_to_your_files1 = r'C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Original\\Yes1'\n",
    "\n",
    "    files_list = sorted(os.listdir(path_to_your_files))\n",
    "    orders = range(3, len(files_list) ,4)\n",
    "    orders1 = range(2, len(files_list) ,4)\n",
    "\n",
    "    for order in orders:\n",
    "        files = files_list[order] \n",
    "        shutil.move(os.path.join(path_to_your_files, files), os.path.join(copy_to_path, files))\n",
    "\n",
    "    for a in orders1:\n",
    "        files = files_list[a] \n",
    "        shutil.move(os.path.join(path_to_your_files, files), os.path.join(copy_to_path, files)) \n",
    "\n",
    "    files_list = sorted(os.listdir(path_to_your_files))\n",
    "    for f in range(Original_Folder_Image_count*2):\n",
    "        files = files_list[f]\n",
    "        shutil.move(os.path.join(path_to_your_files1, files), os.path.join(copy_to_path1, files)) \n",
    "    Folder = r\"C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Lowers\"\n",
    "    for g in range(2):\n",
    "        file_name = glob.glob(Folder +'/'+str(class_names1[i])+'/*')\n",
    "        names=[]\n",
    "        for path in file_name:\n",
    "            foldername=os.path.basename(path)\n",
    "            names.append(foldername)\n",
    "        for h in range(Original_Folder_Image_count):  \n",
    "            path = Folder + \"/\" + str(class_names1[i]) + \"/\" + str(names[j]) \n",
    "            img = Image.open(path)\n",
    "            gray_image = ImageOps.grayscale(img)\n",
    "            PATH = glob.glob(path) \n",
    "            y_train.append(g)\n",
    "    Folder1 = r\"C:\\Users\\Waqar\\Desktop\\zeeshan\\DELL PC\\DELL PC\\One\\Uppers\" \n",
    "    for g1 in range(2):\n",
    "        file_name = glob.glob(Folder1 +'/'+str(class_names2[i])+'/*')\n",
    "        names=[]\n",
    "        for path in file_name:\n",
    "            foldername=os.path.basename(path)\n",
    "            names.append(foldername)\n",
    "        for h in range(Original_Folder_Image_count):  \n",
    "            path = Folder1 + \"/\" + str(class_names2[i]) + \"/\" + str(names[j]) \n",
    "            img = Image.open(path)\n",
    "            gray_image = ImageOps.grayscale(img)\n",
    "            PATH = glob.glob(path)\n",
    "            y_train1.append(g1)\n",
    "\n",
    "    return ((np.array(x_train),np.array(y_train)) , (np.array(x_train1),np.array(y_train1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "y_train1 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train) ,(x_train1,y_train1) = load_data()\n",
    "\n",
    "print('y_train :' , y_train)\n",
    "print('y_train1 :' , y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_classes = 2\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 64, 64, 2)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing \n",
    "\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (800, 64, 64, 2)\n",
      "x_train1 : (800, 64, 64, 2)\n",
      "800 train samples\n",
      "200 test samples\n",
      "800 train1 samples\n",
      "200 test1 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_test=[]\n",
    "y_test=[] \n",
    "x_test1=[]\n",
    "y_test1=[]\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x_train1, y_train1, test_size=0.2)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_train1 = x_train1.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_test1 = x_test1.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_train1 /= 255\n",
    "x_test /= 255\n",
    "x_test1 /= 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],64, 64, 2) #upper region\n",
    "x_test  = x_test.reshape(x_test.shape[0],64,64, 2)\n",
    "x_train1 = x_train1.reshape(x_train1.shape[0],64, 64, 2) #lower region\n",
    "x_test1 = x_test1.reshape(x_test1.shape[0],64, 64, 2)\n",
    "\n",
    "print('x_train :', x_train.shape)\n",
    "print('x_train1 :', x_train1.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_train1.shape[0], 'train1 samples')\n",
    "print(x_test1.shape[0], 'test1 samples')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes) #no. of classes -> 0 (no fluid) & 1 (fluid) => \n",
    "y_test  = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_train1 = keras.utils.to_categorical(y_train1, num_classes)\n",
    "y_test1  = keras.utils.to_categorical(y_test1, num_classes) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#input_layer = Input((64, 64, 2)) # NO NEED TO REPEAT\n",
    "#input_layer1 = Input((64, 64, 2))\n",
    "\n",
    "def build_model(input_layer, start_neurons):\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer) #flattening the matrices\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "    \n",
    "    # Middle -> reverse traversal\n",
    "    convm = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    convm = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n",
    "    \n",
    "    # STEP 3 dECONVULATION -> PAPA'S PRINCESS\n",
    "    deconv1= Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.5)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    \n",
    "     \n",
    "    W1= [0.4]\n",
    "    W2 = [0.8]\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1) #sigmoid function is used to return the bool daa based of real numbers  \n",
    "    output_layer1 = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    R1= output_layer*W1\n",
    "    R2= output_layer1*W2\n",
    "  \n",
    "    out = Flatten()(R1)\n",
    "    out1 =Flatten()(R2)\n",
    "    merge = concatenate([out, out1])\n",
    "    out_put = Dense(2)(merge)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs= out_put)\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 5.0474 - mean_absolute_error: 1.8698 - acc: 0.4938 - val_loss: 3.1984 - val_mean_absolute_error: 1.7158 - val_acc: 0.5550\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 7s 8ms/sample - loss: 1.0679 - mean_absolute_error: 0.8575 - acc: 0.5113 - val_loss: 0.3632 - val_mean_absolute_error: 0.4791 - val_acc: 0.5550\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.4105 - mean_absolute_error: 0.5191 - acc: 0.5362 - val_loss: 0.3038 - val_mean_absolute_error: 0.4844 - val_acc: 0.5550\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.2826 - mean_absolute_error: 0.4986 - acc: 0.5075 - val_loss: 0.2739 - val_mean_absolute_error: 0.5074 - val_acc: 0.4450\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.2600 - mean_absolute_error: 0.4958 - acc: 0.5213 - val_loss: 0.2484 - val_mean_absolute_error: 0.4832 - val_acc: 0.5550\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 7s 8ms/sample - loss: 0.2531 - mean_absolute_error: 0.4861 - acc: 0.5387 - val_loss: 0.2699 - val_mean_absolute_error: 0.5032 - val_acc: 0.4350\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.2406 - mean_absolute_error: 0.4712 - acc: 0.5987 - val_loss: 0.2430 - val_mean_absolute_error: 0.4793 - val_acc: 0.6100\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.2310 - mean_absolute_error: 0.4652 - acc: 0.6237 - val_loss: 0.2433 - val_mean_absolute_error: 0.4830 - val_acc: 0.6000\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.2241 - mean_absolute_error: 0.4549 - acc: 0.6637 - val_loss: 0.2539 - val_mean_absolute_error: 0.4838 - val_acc: 0.5300\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.2230 - mean_absolute_error: 0.4432 - acc: 0.6525 - val_loss: 0.2374 - val_mean_absolute_error: 0.4571 - val_acc: 0.6250\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.2191 - mean_absolute_error: 0.4353 - acc: 0.6338 - val_loss: 0.2315 - val_mean_absolute_error: 0.4489 - val_acc: 0.6400\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.2106 - mean_absolute_error: 0.4253 - acc: 0.6862 - val_loss: 0.2515 - val_mean_absolute_error: 0.4577 - val_acc: 0.5650\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.2057 - mean_absolute_error: 0.4161 - acc: 0.7113 - val_loss: 0.2195 - val_mean_absolute_error: 0.4305 - val_acc: 0.6850\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.1977 - mean_absolute_error: 0.4047 - acc: 0.6975 - val_loss: 0.2167 - val_mean_absolute_error: 0.4192 - val_acc: 0.6950\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.2129 - mean_absolute_error: 0.3945 - acc: 0.6775 - val_loss: 0.2168 - val_mean_absolute_error: 0.4060 - val_acc: 0.7050\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2022 - mean_absolute_error: 0.3875 - acc: 0.6963 - val_loss: 0.2197 - val_mean_absolute_error: 0.4057 - val_acc: 0.6700\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1920 - mean_absolute_error: 0.3767 - acc: 0.7262 - val_loss: 0.2738 - val_mean_absolute_error: 0.4394 - val_acc: 0.5650\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2064 - mean_absolute_error: 0.3910 - acc: 0.7125 - val_loss: 0.2145 - val_mean_absolute_error: 0.4003 - val_acc: 0.6900\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1906 - mean_absolute_error: 0.3717 - acc: 0.7375 - val_loss: 0.2298 - val_mean_absolute_error: 0.4066 - val_acc: 0.6650\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1903 - mean_absolute_error: 0.3729 - acc: 0.7525 - val_loss: 0.2230 - val_mean_absolute_error: 0.4004 - val_acc: 0.6650\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1915 - mean_absolute_error: 0.3709 - acc: 0.7337 - val_loss: 0.2145 - val_mean_absolute_error: 0.3930 - val_acc: 0.6850\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1944 - mean_absolute_error: 0.3698 - acc: 0.7262 - val_loss: 0.2601 - val_mean_absolute_error: 0.4227 - val_acc: 0.6150\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1856 - mean_absolute_error: 0.3607 - acc: 0.7337 - val_loss: 0.2255 - val_mean_absolute_error: 0.3999 - val_acc: 0.6850\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1884 - mean_absolute_error: 0.3694 - acc: 0.7188 - val_loss: 0.2169 - val_mean_absolute_error: 0.3992 - val_acc: 0.6700\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1961 - mean_absolute_error: 0.3724 - acc: 0.7500 - val_loss: 0.2559 - val_mean_absolute_error: 0.4181 - val_acc: 0.6200\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1876 - mean_absolute_error: 0.3647 - acc: 0.7375 - val_loss: 0.2142 - val_mean_absolute_error: 0.3926 - val_acc: 0.6800\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1783 - mean_absolute_error: 0.3612 - acc: 0.7525 - val_loss: 0.2087 - val_mean_absolute_error: 0.3909 - val_acc: 0.6850\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1799 - mean_absolute_error: 0.3616 - acc: 0.7487 - val_loss: 0.2215 - val_mean_absolute_error: 0.3908 - val_acc: 0.6550\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1851 - mean_absolute_error: 0.3661 - acc: 0.7525 - val_loss: 0.2235 - val_mean_absolute_error: 0.3963 - val_acc: 0.6500\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1765 - mean_absolute_error: 0.3564 - acc: 0.7550 - val_loss: 0.2373 - val_mean_absolute_error: 0.4019 - val_acc: 0.6300\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1823 - mean_absolute_error: 0.3571 - acc: 0.7375 - val_loss: 0.2013 - val_mean_absolute_error: 0.3827 - val_acc: 0.7300\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1766 - mean_absolute_error: 0.3538 - acc: 0.7487 - val_loss: 0.2008 - val_mean_absolute_error: 0.3789 - val_acc: 0.7100\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1819 - mean_absolute_error: 0.3554 - acc: 0.7500 - val_loss: 0.2174 - val_mean_absolute_error: 0.3907 - val_acc: 0.6500\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1812 - mean_absolute_error: 0.3659 - acc: 0.7613 - val_loss: 0.2086 - val_mean_absolute_error: 0.3911 - val_acc: 0.6650\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1818 - mean_absolute_error: 0.3551 - acc: 0.7588 - val_loss: 0.2203 - val_mean_absolute_error: 0.3881 - val_acc: 0.6450\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1806 - mean_absolute_error: 0.3524 - acc: 0.7513 - val_loss: 0.2003 - val_mean_absolute_error: 0.3851 - val_acc: 0.7250\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1762 - mean_absolute_error: 0.3558 - acc: 0.7525 - val_loss: 0.2078 - val_mean_absolute_error: 0.3797 - val_acc: 0.6700\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1773 - mean_absolute_error: 0.3475 - acc: 0.7575 - val_loss: 0.2056 - val_mean_absolute_error: 0.3806 - val_acc: 0.6650\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1779 - mean_absolute_error: 0.3561 - acc: 0.7563 - val_loss: 0.1960 - val_mean_absolute_error: 0.3794 - val_acc: 0.7150\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1794 - mean_absolute_error: 0.3575 - acc: 0.7550 - val_loss: 0.1950 - val_mean_absolute_error: 0.3732 - val_acc: 0.7300\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1741 - mean_absolute_error: 0.3457 - acc: 0.7500 - val_loss: 0.1955 - val_mean_absolute_error: 0.3810 - val_acc: 0.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1835 - mean_absolute_error: 0.3646 - acc: 0.7538 - val_loss: 0.1956 - val_mean_absolute_error: 0.3773 - val_acc: 0.7400\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1753 - mean_absolute_error: 0.3531 - acc: 0.7550 - val_loss: 0.1908 - val_mean_absolute_error: 0.3722 - val_acc: 0.7100\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1825 - mean_absolute_error: 0.3516 - acc: 0.7437 - val_loss: 0.1958 - val_mean_absolute_error: 0.3701 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1722 - mean_absolute_error: 0.3444 - acc: 0.7613 - val_loss: 0.1913 - val_mean_absolute_error: 0.3752 - val_acc: 0.7150\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1721 - mean_absolute_error: 0.3484 - acc: 0.7625 - val_loss: 0.1934 - val_mean_absolute_error: 0.3658 - val_acc: 0.7050\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1694 - mean_absolute_error: 0.3409 - acc: 0.7763 - val_loss: 0.1888 - val_mean_absolute_error: 0.3683 - val_acc: 0.7400\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1688 - mean_absolute_error: 0.3509 - acc: 0.7613 - val_loss: 0.1920 - val_mean_absolute_error: 0.3679 - val_acc: 0.7100\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1702 - mean_absolute_error: 0.3381 - acc: 0.7713 - val_loss: 0.1978 - val_mean_absolute_error: 0.3703 - val_acc: 0.7250\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1707 - mean_absolute_error: 0.3468 - acc: 0.7738 - val_loss: 0.1865 - val_mean_absolute_error: 0.3674 - val_acc: 0.7350\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1680 - mean_absolute_error: 0.3457 - acc: 0.7663 - val_loss: 0.2030 - val_mean_absolute_error: 0.3734 - val_acc: 0.6950\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1719 - mean_absolute_error: 0.3420 - acc: 0.7613 - val_loss: 0.1873 - val_mean_absolute_error: 0.3639 - val_acc: 0.7100\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1680 - mean_absolute_error: 0.3426 - acc: 0.7700 - val_loss: 0.1884 - val_mean_absolute_error: 0.3616 - val_acc: 0.7150\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1684 - mean_absolute_error: 0.3418 - acc: 0.7513 - val_loss: 0.2144 - val_mean_absolute_error: 0.3838 - val_acc: 0.6750\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1669 - mean_absolute_error: 0.3369 - acc: 0.7588 - val_loss: 0.1888 - val_mean_absolute_error: 0.3599 - val_acc: 0.7250\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1678 - mean_absolute_error: 0.3391 - acc: 0.7550 - val_loss: 0.1828 - val_mean_absolute_error: 0.3642 - val_acc: 0.7400\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1700 - mean_absolute_error: 0.3445 - acc: 0.7663 - val_loss: 0.1946 - val_mean_absolute_error: 0.3655 - val_acc: 0.7200\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1701 - mean_absolute_error: 0.3387 - acc: 0.7638 - val_loss: 0.1917 - val_mean_absolute_error: 0.3652 - val_acc: 0.7200\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1726 - mean_absolute_error: 0.3472 - acc: 0.7525 - val_loss: 0.1942 - val_mean_absolute_error: 0.3743 - val_acc: 0.7100\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1859 - mean_absolute_error: 0.3614 - acc: 0.7337 - val_loss: 0.2110 - val_mean_absolute_error: 0.3808 - val_acc: 0.6850\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1742 - mean_absolute_error: 0.3465 - acc: 0.7650 - val_loss: 0.1815 - val_mean_absolute_error: 0.3650 - val_acc: 0.7250\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1648 - mean_absolute_error: 0.3386 - acc: 0.7812 - val_loss: 0.2022 - val_mean_absolute_error: 0.3703 - val_acc: 0.7050\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1665 - mean_absolute_error: 0.3384 - acc: 0.7750 - val_loss: 0.1817 - val_mean_absolute_error: 0.3606 - val_acc: 0.7250\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1647 - mean_absolute_error: 0.3380 - acc: 0.7663 - val_loss: 0.1892 - val_mean_absolute_error: 0.3651 - val_acc: 0.7250\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1637 - mean_absolute_error: 0.3319 - acc: 0.7775 - val_loss: 0.2130 - val_mean_absolute_error: 0.3815 - val_acc: 0.6800\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1641 - mean_absolute_error: 0.3389 - acc: 0.7725 - val_loss: 0.1819 - val_mean_absolute_error: 0.3632 - val_acc: 0.7300\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1650 - mean_absolute_error: 0.3367 - acc: 0.7688 - val_loss: 0.1838 - val_mean_absolute_error: 0.3580 - val_acc: 0.7300\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1633 - mean_absolute_error: 0.3310 - acc: 0.7650 - val_loss: 0.2171 - val_mean_absolute_error: 0.3856 - val_acc: 0.6850\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1677 - mean_absolute_error: 0.3369 - acc: 0.7600 - val_loss: 0.1889 - val_mean_absolute_error: 0.3650 - val_acc: 0.7300\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1607 - mean_absolute_error: 0.3380 - acc: 0.7750 - val_loss: 0.1876 - val_mean_absolute_error: 0.3590 - val_acc: 0.7350\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1702 - mean_absolute_error: 0.3370 - acc: 0.7713 - val_loss: 0.1848 - val_mean_absolute_error: 0.3632 - val_acc: 0.7100\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1624 - mean_absolute_error: 0.3333 - acc: 0.7725 - val_loss: 0.1837 - val_mean_absolute_error: 0.3590 - val_acc: 0.7400\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1623 - mean_absolute_error: 0.3323 - acc: 0.7812 - val_loss: 0.1888 - val_mean_absolute_error: 0.3672 - val_acc: 0.7400\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1675 - mean_absolute_error: 0.3438 - acc: 0.7550 - val_loss: 0.1856 - val_mean_absolute_error: 0.3594 - val_acc: 0.7300\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1611 - mean_absolute_error: 0.3271 - acc: 0.7713 - val_loss: 0.2099 - val_mean_absolute_error: 0.3816 - val_acc: 0.6900\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1604 - mean_absolute_error: 0.3331 - acc: 0.7675 - val_loss: 0.1894 - val_mean_absolute_error: 0.3633 - val_acc: 0.7200\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1589 - mean_absolute_error: 0.3268 - acc: 0.7825 - val_loss: 0.1875 - val_mean_absolute_error: 0.3623 - val_acc: 0.7350\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1578 - mean_absolute_error: 0.3300 - acc: 0.7750 - val_loss: 0.1854 - val_mean_absolute_error: 0.3636 - val_acc: 0.7300\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1530 - mean_absolute_error: 0.3225 - acc: 0.7850 - val_loss: 0.1889 - val_mean_absolute_error: 0.3621 - val_acc: 0.7200\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1566 - mean_absolute_error: 0.3239 - acc: 0.7775 - val_loss: 0.1817 - val_mean_absolute_error: 0.3594 - val_acc: 0.7400\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1529 - mean_absolute_error: 0.3251 - acc: 0.7812 - val_loss: 0.1990 - val_mean_absolute_error: 0.3771 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1562 - mean_absolute_error: 0.3266 - acc: 0.7775 - val_loss: 0.1878 - val_mean_absolute_error: 0.3650 - val_acc: 0.7450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1641 - mean_absolute_error: 0.3339 - acc: 0.7688 - val_loss: 0.2282 - val_mean_absolute_error: 0.4008 - val_acc: 0.6650\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1602 - mean_absolute_error: 0.3353 - acc: 0.7750 - val_loss: 0.1881 - val_mean_absolute_error: 0.3624 - val_acc: 0.7250\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1514 - mean_absolute_error: 0.3180 - acc: 0.7862 - val_loss: 0.1859 - val_mean_absolute_error: 0.3658 - val_acc: 0.7200\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1575 - mean_absolute_error: 0.3236 - acc: 0.7738 - val_loss: 0.1922 - val_mean_absolute_error: 0.3735 - val_acc: 0.7150\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1511 - mean_absolute_error: 0.3202 - acc: 0.7875 - val_loss: 0.2021 - val_mean_absolute_error: 0.3827 - val_acc: 0.6850\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1507 - mean_absolute_error: 0.3243 - acc: 0.7738 - val_loss: 0.1932 - val_mean_absolute_error: 0.3692 - val_acc: 0.7200\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1485 - mean_absolute_error: 0.3135 - acc: 0.8025 - val_loss: 0.1930 - val_mean_absolute_error: 0.3714 - val_acc: 0.7150\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1480 - mean_absolute_error: 0.3144 - acc: 0.8075 - val_loss: 0.1939 - val_mean_absolute_error: 0.3749 - val_acc: 0.7150\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1510 - mean_absolute_error: 0.3190 - acc: 0.7937 - val_loss: 0.1871 - val_mean_absolute_error: 0.3671 - val_acc: 0.7100\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1516 - mean_absolute_error: 0.3179 - acc: 0.7987 - val_loss: 0.1888 - val_mean_absolute_error: 0.3704 - val_acc: 0.7100\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1431 - mean_absolute_error: 0.3111 - acc: 0.8112 - val_loss: 0.1910 - val_mean_absolute_error: 0.3675 - val_acc: 0.7150\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1476 - mean_absolute_error: 0.3160 - acc: 0.7925 - val_loss: 0.2034 - val_mean_absolute_error: 0.3803 - val_acc: 0.6850\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1441 - mean_absolute_error: 0.3093 - acc: 0.8037 - val_loss: 0.1929 - val_mean_absolute_error: 0.3678 - val_acc: 0.7050\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.1423 - mean_absolute_error: 0.3091 - acc: 0.8125 - val_loss: 0.1879 - val_mean_absolute_error: 0.3693 - val_acc: 0.7200\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 9s 11ms/sample - loss: 0.1380 - mean_absolute_error: 0.3041 - acc: 0.8050 - val_loss: 0.1932 - val_mean_absolute_error: 0.3738 - val_acc: 0.7250\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 8s 9ms/sample - loss: 0.1436 - mean_absolute_error: 0.3110 - acc: 0.8087 - val_loss: 0.1915 - val_mean_absolute_error: 0.3706 - val_acc: 0.7100\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 7s 9ms/sample - loss: 0.1416 - mean_absolute_error: 0.3053 - acc: 0.7987 - val_loss: 0.2006 - val_mean_absolute_error: 0.3717 - val_acc: 0.7050\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 7s 8ms/sample - loss: 0.1486 - mean_absolute_error: 0.3166 - acc: 0.7912 - val_loss: 0.1950 - val_mean_absolute_error: 0.3754 - val_acc: 0.6950\n",
      "200/200 [==============================] - 1s 3ms/sample - loss: 0.1950 - mean_absolute_error: 0.3754 - acc: 0.6950\n",
      "Test loss: 0.19502910673618318\n",
      "Test accuracy: 0.37536237\n",
      "Evaluate on test data\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.1950 - mean_absolute_error: 0.3754 - acc: 0.6950\n",
      "test loss, test acc: [0.1950291085243225, 0.3753624, 0.695]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (20, 2)\n"
     ]
    }
   ],
   "source": [
    "#Model 1\n",
    "\n",
    "input_layer = Input((64, 64, 2))\n",
    "model = build_model(input_layer, 4)\n",
    "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "\n",
    "\n",
    "hist= model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "scores = model.evaluate(x_test, y_test,verbose=1)\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "########################Keras LIbraray Code#############\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:20])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 4.4731 - mean_absolute_error: 1.7613 - acc: 0.5100 - val_loss: 2.3299 - val_mean_absolute_error: 1.4010 - val_acc: 0.5200\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.9228 - mean_absolute_error: 0.7854 - acc: 0.4762 - val_loss: 0.4132 - val_mean_absolute_error: 0.5274 - val_acc: 0.5200\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.3743 - mean_absolute_error: 0.5151 - acc: 0.5238 - val_loss: 0.2889 - val_mean_absolute_error: 0.5016 - val_acc: 0.4800\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.2827 - mean_absolute_error: 0.5019 - acc: 0.4988 - val_loss: 0.2765 - val_mean_absolute_error: 0.4980 - val_acc: 0.4800\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.2532 - mean_absolute_error: 0.4912 - acc: 0.5425 - val_loss: 0.2432 - val_mean_absolute_error: 0.4883 - val_acc: 0.6050\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.2507 - mean_absolute_error: 0.4895 - acc: 0.5475 - val_loss: 0.2396 - val_mean_absolute_error: 0.4836 - val_acc: 0.6300\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.2411 - mean_absolute_error: 0.4812 - acc: 0.5975 - val_loss: 0.2384 - val_mean_absolute_error: 0.4789 - val_acc: 0.5750\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.2442 - mean_absolute_error: 0.4790 - acc: 0.5825 - val_loss: 0.2324 - val_mean_absolute_error: 0.4726 - val_acc: 0.6200\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.2393 - mean_absolute_error: 0.4725 - acc: 0.5962 - val_loss: 0.2261 - val_mean_absolute_error: 0.4645 - val_acc: 0.6500\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2366 - mean_absolute_error: 0.4637 - acc: 0.6150 - val_loss: 0.2221 - val_mean_absolute_error: 0.4588 - val_acc: 0.6600\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2267 - mean_absolute_error: 0.4548 - acc: 0.6525 - val_loss: 0.2257 - val_mean_absolute_error: 0.4559 - val_acc: 0.6450\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2270 - mean_absolute_error: 0.4510 - acc: 0.6375 - val_loss: 0.2249 - val_mean_absolute_error: 0.4511 - val_acc: 0.6500\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2247 - mean_absolute_error: 0.4499 - acc: 0.6600 - val_loss: 0.2217 - val_mean_absolute_error: 0.4412 - val_acc: 0.6000\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2204 - mean_absolute_error: 0.4440 - acc: 0.6762 - val_loss: 0.2115 - val_mean_absolute_error: 0.4393 - val_acc: 0.6800\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2169 - mean_absolute_error: 0.4396 - acc: 0.6837 - val_loss: 0.2089 - val_mean_absolute_error: 0.4353 - val_acc: 0.6700\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2133 - mean_absolute_error: 0.4350 - acc: 0.7000 - val_loss: 0.2073 - val_mean_absolute_error: 0.4316 - val_acc: 0.6850\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2122 - mean_absolute_error: 0.4233 - acc: 0.6750 - val_loss: 0.2071 - val_mean_absolute_error: 0.4244 - val_acc: 0.6800\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2241 - mean_absolute_error: 0.4283 - acc: 0.6625 - val_loss: 0.2181 - val_mean_absolute_error: 0.4187 - val_acc: 0.6150\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2083 - mean_absolute_error: 0.4158 - acc: 0.7100 - val_loss: 0.2053 - val_mean_absolute_error: 0.4166 - val_acc: 0.6800\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2127 - mean_absolute_error: 0.4161 - acc: 0.7088 - val_loss: 0.2053 - val_mean_absolute_error: 0.4142 - val_acc: 0.6850\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2072 - mean_absolute_error: 0.4135 - acc: 0.7075 - val_loss: 0.2051 - val_mean_absolute_error: 0.4180 - val_acc: 0.7100\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2048 - mean_absolute_error: 0.4127 - acc: 0.7000 - val_loss: 0.1998 - val_mean_absolute_error: 0.4095 - val_acc: 0.7050\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2047 - mean_absolute_error: 0.4063 - acc: 0.7025 - val_loss: 0.1982 - val_mean_absolute_error: 0.4037 - val_acc: 0.7000\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1998 - mean_absolute_error: 0.3967 - acc: 0.7088 - val_loss: 0.2058 - val_mean_absolute_error: 0.3979 - val_acc: 0.6700\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2044 - mean_absolute_error: 0.3992 - acc: 0.6938 - val_loss: 0.2083 - val_mean_absolute_error: 0.4015 - val_acc: 0.6800\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2031 - mean_absolute_error: 0.3991 - acc: 0.7025 - val_loss: 0.2002 - val_mean_absolute_error: 0.3963 - val_acc: 0.6950\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1996 - mean_absolute_error: 0.3942 - acc: 0.6963 - val_loss: 0.1980 - val_mean_absolute_error: 0.3977 - val_acc: 0.7150\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1987 - mean_absolute_error: 0.3990 - acc: 0.7025 - val_loss: 0.1966 - val_mean_absolute_error: 0.3995 - val_acc: 0.7150\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1958 - mean_absolute_error: 0.3936 - acc: 0.7063 - val_loss: 0.1951 - val_mean_absolute_error: 0.3965 - val_acc: 0.7100\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2004 - mean_absolute_error: 0.3879 - acc: 0.7025 - val_loss: 0.1976 - val_mean_absolute_error: 0.3868 - val_acc: 0.7000\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1939 - mean_absolute_error: 0.3855 - acc: 0.7175 - val_loss: 0.1937 - val_mean_absolute_error: 0.3909 - val_acc: 0.7100\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1951 - mean_absolute_error: 0.3884 - acc: 0.6963 - val_loss: 0.1991 - val_mean_absolute_error: 0.3922 - val_acc: 0.7000\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1932 - mean_absolute_error: 0.3845 - acc: 0.7200 - val_loss: 0.1941 - val_mean_absolute_error: 0.3849 - val_acc: 0.6900\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1958 - mean_absolute_error: 0.3898 - acc: 0.7113 - val_loss: 0.2190 - val_mean_absolute_error: 0.3946 - val_acc: 0.6750\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2114 - mean_absolute_error: 0.3930 - acc: 0.6800 - val_loss: 0.2015 - val_mean_absolute_error: 0.4039 - val_acc: 0.7200\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1975 - mean_absolute_error: 0.3987 - acc: 0.7175 - val_loss: 0.2012 - val_mean_absolute_error: 0.3871 - val_acc: 0.7200\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1936 - mean_absolute_error: 0.3912 - acc: 0.7188 - val_loss: 0.1923 - val_mean_absolute_error: 0.3853 - val_acc: 0.6950\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1937 - mean_absolute_error: 0.3816 - acc: 0.7100 - val_loss: 0.2188 - val_mean_absolute_error: 0.3867 - val_acc: 0.6700\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1931 - mean_absolute_error: 0.3822 - acc: 0.7237 - val_loss: 0.1939 - val_mean_absolute_error: 0.3824 - val_acc: 0.7050\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1926 - mean_absolute_error: 0.3810 - acc: 0.7138 - val_loss: 0.1920 - val_mean_absolute_error: 0.3861 - val_acc: 0.7200\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1929 - mean_absolute_error: 0.3898 - acc: 0.7088 - val_loss: 0.1947 - val_mean_absolute_error: 0.3802 - val_acc: 0.6950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1947 - mean_absolute_error: 0.3808 - acc: 0.7150 - val_loss: 0.1941 - val_mean_absolute_error: 0.3775 - val_acc: 0.7200\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1896 - mean_absolute_error: 0.3779 - acc: 0.7262 - val_loss: 0.1947 - val_mean_absolute_error: 0.3764 - val_acc: 0.6650\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1896 - mean_absolute_error: 0.3787 - acc: 0.7375 - val_loss: 0.1951 - val_mean_absolute_error: 0.3779 - val_acc: 0.7200\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1935 - mean_absolute_error: 0.3817 - acc: 0.7237 - val_loss: 0.1921 - val_mean_absolute_error: 0.3756 - val_acc: 0.7050\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1848 - mean_absolute_error: 0.3741 - acc: 0.7400 - val_loss: 0.1910 - val_mean_absolute_error: 0.3715 - val_acc: 0.7150\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1855 - mean_absolute_error: 0.3709 - acc: 0.7300 - val_loss: 0.1953 - val_mean_absolute_error: 0.3712 - val_acc: 0.6850\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1842 - mean_absolute_error: 0.3680 - acc: 0.7337 - val_loss: 0.1944 - val_mean_absolute_error: 0.3707 - val_acc: 0.7300\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1879 - mean_absolute_error: 0.3707 - acc: 0.7300 - val_loss: 0.1876 - val_mean_absolute_error: 0.3701 - val_acc: 0.7050\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1866 - mean_absolute_error: 0.3719 - acc: 0.7088 - val_loss: 0.1913 - val_mean_absolute_error: 0.3738 - val_acc: 0.7100\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1877 - mean_absolute_error: 0.3716 - acc: 0.7212 - val_loss: 0.1911 - val_mean_absolute_error: 0.3719 - val_acc: 0.6950\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1831 - mean_absolute_error: 0.3696 - acc: 0.7350 - val_loss: 0.1922 - val_mean_absolute_error: 0.3670 - val_acc: 0.7250\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1911 - mean_absolute_error: 0.3743 - acc: 0.7025 - val_loss: 0.2159 - val_mean_absolute_error: 0.3878 - val_acc: 0.6950\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1894 - mean_absolute_error: 0.3822 - acc: 0.7337 - val_loss: 0.2029 - val_mean_absolute_error: 0.3706 - val_acc: 0.7350\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1800 - mean_absolute_error: 0.3548 - acc: 0.7375 - val_loss: 0.1904 - val_mean_absolute_error: 0.3645 - val_acc: 0.7250\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1785 - mean_absolute_error: 0.3651 - acc: 0.7337 - val_loss: 0.2108 - val_mean_absolute_error: 0.3797 - val_acc: 0.6900\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1880 - mean_absolute_error: 0.3691 - acc: 0.7337 - val_loss: 0.1994 - val_mean_absolute_error: 0.3808 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1831 - mean_absolute_error: 0.3677 - acc: 0.7500 - val_loss: 0.1887 - val_mean_absolute_error: 0.3627 - val_acc: 0.7050\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1774 - mean_absolute_error: 0.3572 - acc: 0.7450 - val_loss: 0.1863 - val_mean_absolute_error: 0.3565 - val_acc: 0.7150\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1784 - mean_absolute_error: 0.3634 - acc: 0.7550 - val_loss: 0.1940 - val_mean_absolute_error: 0.3640 - val_acc: 0.6900\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1784 - mean_absolute_error: 0.3590 - acc: 0.7437 - val_loss: 0.1914 - val_mean_absolute_error: 0.3658 - val_acc: 0.7200\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1762 - mean_absolute_error: 0.3589 - acc: 0.7513 - val_loss: 0.1883 - val_mean_absolute_error: 0.3575 - val_acc: 0.7300\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1790 - mean_absolute_error: 0.3562 - acc: 0.7475 - val_loss: 0.1999 - val_mean_absolute_error: 0.3685 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1763 - mean_absolute_error: 0.3607 - acc: 0.7613 - val_loss: 0.2085 - val_mean_absolute_error: 0.3706 - val_acc: 0.7000\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1792 - mean_absolute_error: 0.3542 - acc: 0.7375 - val_loss: 0.1886 - val_mean_absolute_error: 0.3561 - val_acc: 0.7450\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1744 - mean_absolute_error: 0.3591 - acc: 0.7625 - val_loss: 0.1905 - val_mean_absolute_error: 0.3608 - val_acc: 0.7300\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1763 - mean_absolute_error: 0.3491 - acc: 0.7525 - val_loss: 0.1903 - val_mean_absolute_error: 0.3583 - val_acc: 0.7350\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1798 - mean_absolute_error: 0.3651 - acc: 0.7400 - val_loss: 0.1974 - val_mean_absolute_error: 0.3669 - val_acc: 0.7200\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1728 - mean_absolute_error: 0.3531 - acc: 0.7563 - val_loss: 0.1891 - val_mean_absolute_error: 0.3616 - val_acc: 0.7250\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1727 - mean_absolute_error: 0.3536 - acc: 0.7663 - val_loss: 0.1930 - val_mean_absolute_error: 0.3635 - val_acc: 0.7300\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1755 - mean_absolute_error: 0.3539 - acc: 0.7450 - val_loss: 0.1896 - val_mean_absolute_error: 0.3567 - val_acc: 0.7100\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1748 - mean_absolute_error: 0.3538 - acc: 0.7425 - val_loss: 0.1894 - val_mean_absolute_error: 0.3561 - val_acc: 0.7250\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1707 - mean_absolute_error: 0.3463 - acc: 0.7663 - val_loss: 0.1917 - val_mean_absolute_error: 0.3622 - val_acc: 0.7200\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1799 - mean_absolute_error: 0.3623 - acc: 0.7412 - val_loss: 0.1885 - val_mean_absolute_error: 0.3697 - val_acc: 0.7350\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1816 - mean_absolute_error: 0.3571 - acc: 0.7525 - val_loss: 0.1902 - val_mean_absolute_error: 0.3637 - val_acc: 0.7250\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1734 - mean_absolute_error: 0.3534 - acc: 0.7688 - val_loss: 0.2070 - val_mean_absolute_error: 0.3775 - val_acc: 0.7050\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1827 - mean_absolute_error: 0.3683 - acc: 0.7475 - val_loss: 0.2032 - val_mean_absolute_error: 0.3711 - val_acc: 0.7100\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1736 - mean_absolute_error: 0.3485 - acc: 0.7563 - val_loss: 0.1952 - val_mean_absolute_error: 0.3663 - val_acc: 0.6900\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1729 - mean_absolute_error: 0.3519 - acc: 0.7475 - val_loss: 0.1941 - val_mean_absolute_error: 0.3631 - val_acc: 0.7050\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1687 - mean_absolute_error: 0.3476 - acc: 0.7663 - val_loss: 0.1955 - val_mean_absolute_error: 0.3703 - val_acc: 0.7200\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1689 - mean_absolute_error: 0.3410 - acc: 0.7487 - val_loss: 0.1927 - val_mean_absolute_error: 0.3600 - val_acc: 0.7100\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1693 - mean_absolute_error: 0.3471 - acc: 0.7538 - val_loss: 0.1974 - val_mean_absolute_error: 0.3671 - val_acc: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1695 - mean_absolute_error: 0.3444 - acc: 0.7600 - val_loss: 0.2062 - val_mean_absolute_error: 0.3814 - val_acc: 0.7050\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1833 - mean_absolute_error: 0.3698 - acc: 0.7462 - val_loss: 0.1961 - val_mean_absolute_error: 0.3638 - val_acc: 0.7150\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.1722 - mean_absolute_error: 0.3449 - acc: 0.7675 - val_loss: 0.1979 - val_mean_absolute_error: 0.3666 - val_acc: 0.7050\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1734 - mean_absolute_error: 0.3532 - acc: 0.7538 - val_loss: 0.1928 - val_mean_absolute_error: 0.3682 - val_acc: 0.7300\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1685 - mean_absolute_error: 0.3462 - acc: 0.7700 - val_loss: 0.1932 - val_mean_absolute_error: 0.3569 - val_acc: 0.7200\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1689 - mean_absolute_error: 0.3445 - acc: 0.7613 - val_loss: 0.1945 - val_mean_absolute_error: 0.3691 - val_acc: 0.7300\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1689 - mean_absolute_error: 0.3474 - acc: 0.7663 - val_loss: 0.1931 - val_mean_absolute_error: 0.3639 - val_acc: 0.7350\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.1681 - mean_absolute_error: 0.3436 - acc: 0.7613 - val_loss: 0.1990 - val_mean_absolute_error: 0.3632 - val_acc: 0.7050\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.1674 - mean_absolute_error: 0.3400 - acc: 0.7713 - val_loss: 0.1934 - val_mean_absolute_error: 0.3669 - val_acc: 0.7350\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1745 - mean_absolute_error: 0.3502 - acc: 0.7575 - val_loss: 0.1987 - val_mean_absolute_error: 0.3704 - val_acc: 0.7000\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1751 - mean_absolute_error: 0.3531 - acc: 0.7437 - val_loss: 0.1967 - val_mean_absolute_error: 0.3668 - val_acc: 0.7000\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1661 - mean_absolute_error: 0.3437 - acc: 0.7700 - val_loss: 0.1956 - val_mean_absolute_error: 0.3673 - val_acc: 0.7200\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1656 - mean_absolute_error: 0.3335 - acc: 0.7788 - val_loss: 0.1937 - val_mean_absolute_error: 0.3647 - val_acc: 0.7100\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1667 - mean_absolute_error: 0.3431 - acc: 0.7738 - val_loss: 0.1940 - val_mean_absolute_error: 0.3674 - val_acc: 0.7300\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1681 - mean_absolute_error: 0.3408 - acc: 0.7563 - val_loss: 0.1937 - val_mean_absolute_error: 0.3659 - val_acc: 0.7350\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1676 - mean_absolute_error: 0.3420 - acc: 0.7763 - val_loss: 0.1946 - val_mean_absolute_error: 0.3678 - val_acc: 0.7300\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.1638 - mean_absolute_error: 0.3369 - acc: 0.7600 - val_loss: 0.2022 - val_mean_absolute_error: 0.3692 - val_acc: 0.7100\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.1744 - mean_absolute_error: 0.3505 - acc: 0.7437 - val_loss: 0.2164 - val_mean_absolute_error: 0.3877 - val_acc: 0.6900\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.2164 - mean_absolute_error: 0.3877 - acc: 0.6900\n",
      "Test loss: 0.21642925798892976\n",
      "Test accuracy: 0.3877381\n",
      "Evaluate on test data\n",
      "200/200 [==============================] - 0s 1ms/sample - loss: 0.5665 - mean_absolute_error: 0.6016 - acc: 0.4700\n",
      "test loss, test acc: [0.566468346118927, 0.6015974, 0.47]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (20, 2)\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "\n",
    "input_layer = Input((64, 64, 2))\n",
    "model2 = build_model(input_layer, 4)\n",
    "model2.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "\n",
    "hist1 = model2.fit(x_train1, y_train1, batch_size=batch_size, epochs=epochs,verbose=1, validation_data=(x_test1, y_test1))\n",
    "\n",
    "scores1 = model2.evaluate(x_test1, y_test1,verbose=1)\n",
    "\n",
    "print('Test loss:', scores1[0])\n",
    "print('Test accuracy:', scores1[1])\n",
    "\n",
    "\n",
    "########################Keras LIbraray Code#############\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test1, y_test1, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test1[:20])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy MOdel 1: [0.49625, 0.50125, 0.47125, 0.51625, 0.48125, 0.47125, 0.4975, 0.47625, 0.48, 0.50125, 0.51375, 0.50625, 0.50625, 0.48625, 0.50375, 0.51375, 0.5025, 0.685, 0.73625, 0.71625, 0.71, 0.72375, 0.72625, 0.74375, 0.7275, 0.75375, 0.67875, 0.74375, 0.70625, 0.73375, 0.69375, 0.7, 0.72625, 0.73125, 0.74375, 0.76625, 0.7575, 0.755, 0.7275, 0.74125, 0.73125, 0.71625, 0.73625, 0.7425, 0.75875, 0.77625, 0.75375, 0.76, 0.7775, 0.785, 0.76, 0.74875, 0.69, 0.73, 0.78, 0.7675, 0.78125, 0.745, 0.71, 0.79375, 0.78, 0.78625, 0.8, 0.77625, 0.7725, 0.7925, 0.8025, 0.82, 0.81375, 0.8, 0.8125, 0.80625, 0.82375, 0.80625, 0.83125, 0.82625, 0.81875, 0.81875, 0.82375, 0.83, 0.825, 0.835, 0.82625, 0.84375, 0.8525, 0.8325, 0.8425, 0.835, 0.87125, 0.85125, 0.84375, 0.84875, 0.86875, 0.8625, 0.8425, 0.86125, 0.85875, 0.865, 0.88, 0.87625]\n",
      "Val accuracy  MOdel 1: [0.445, 0.555, 0.445, 0.555, 0.445, 0.445, 0.555, 0.445, 0.445, 0.555, 0.555, 0.445, 0.445, 0.555, 0.555, 0.445, 0.565, 0.655, 0.705, 0.725, 0.73, 0.71, 0.72, 0.685, 0.67, 0.685, 0.715, 0.64, 0.7, 0.745, 0.67, 0.745, 0.7, 0.735, 0.675, 0.745, 0.72, 0.745, 0.705, 0.655, 0.665, 0.7, 0.705, 0.665, 0.75, 0.75, 0.73, 0.73, 0.725, 0.705, 0.705, 0.69, 0.49, 0.71, 0.715, 0.71, 0.71, 0.55, 0.72, 0.71, 0.71, 0.725, 0.725, 0.7, 0.71, 0.72, 0.73, 0.73, 0.705, 0.735, 0.7, 0.735, 0.73, 0.72, 0.725, 0.72, 0.715, 0.725, 0.72, 0.7, 0.72, 0.73, 0.715, 0.72, 0.71, 0.705, 0.695, 0.71, 0.7, 0.69, 0.685, 0.69, 0.67, 0.69, 0.695, 0.705, 0.69, 0.685, 0.675, 0.67]\n",
      "Test Accuracy MOdel 2: [0.52875, 0.58125, 0.60125, 0.6275, 0.68, 0.6725, 0.69, 0.70375, 0.7275, 0.72125, 0.745, 0.73125, 0.73, 0.75625, 0.75125, 0.77875, 0.7575, 0.76375, 0.77125, 0.7725, 0.78125, 0.77375, 0.79125, 0.79125, 0.79875, 0.7975, 0.79875, 0.79625, 0.79375, 0.81875, 0.81, 0.8, 0.79875, 0.8125, 0.825, 0.8, 0.83375, 0.82625, 0.835, 0.82375, 0.82875, 0.835, 0.84375, 0.83625, 0.82875, 0.84125, 0.85875, 0.85125, 0.835, 0.8525, 0.855, 0.84875, 0.85375, 0.875, 0.865, 0.84875, 0.86625, 0.8675, 0.8725, 0.86375, 0.8725, 0.87, 0.87125, 0.8825, 0.87375, 0.8675, 0.885, 0.88, 0.8875, 0.90125, 0.90125, 0.88875, 0.8975, 0.8925, 0.89875, 0.89625, 0.9075, 0.8925, 0.90375, 0.9, 0.9075, 0.905, 0.92125, 0.90875, 0.90375, 0.91625, 0.9075, 0.92, 0.91375, 0.92125, 0.92375, 0.93125, 0.92625, 0.9, 0.9225, 0.92, 0.925, 0.93375, 0.92375, 0.935]\n",
      "Val accuracy  MOdel 2: [0.545, 0.54, 0.66, 0.65, 0.665, 0.67, 0.7, 0.695, 0.68, 0.685, 0.69, 0.72, 0.7, 0.72, 0.73, 0.735, 0.73, 0.735, 0.72, 0.725, 0.73, 0.73, 0.73, 0.715, 0.72, 0.72, 0.715, 0.715, 0.73, 0.715, 0.73, 0.725, 0.73, 0.72, 0.735, 0.72, 0.73, 0.68, 0.72, 0.72, 0.705, 0.705, 0.72, 0.725, 0.695, 0.705, 0.73, 0.73, 0.705, 0.725, 0.705, 0.735, 0.71, 0.7, 0.715, 0.725, 0.71, 0.725, 0.71, 0.715, 0.695, 0.71, 0.7, 0.715, 0.72, 0.725, 0.715, 0.72, 0.705, 0.71, 0.73, 0.72, 0.71, 0.72, 0.71, 0.73, 0.715, 0.71, 0.715, 0.73, 0.72, 0.715, 0.705, 0.74, 0.7, 0.715, 0.7, 0.72, 0.7, 0.71, 0.745, 0.71, 0.705, 0.725, 0.73, 0.725, 0.72, 0.735, 0.745, 0.73]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Test Accuracy MOdel 1:', hist.history['acc'])\n",
    "print('Val accuracy  MOdel 1:',hist.history['val_acc'])\n",
    "print('Test Accuracy MOdel 2:', hist1.history['acc'])\n",
    "print('Val accuracy  MOdel 2:',hist1.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_pred= model.predict(x_test)\n",
    "y_true= y_test\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_true=np.argmax(y_test, axis=1)\n",
    "\n",
    "cm=confusion_matrix(y_true,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cm = np.array([[41,0],[13,30]])\n",
    "sns.heatmap(cm,annot=True,linecolor=\"white\",annot_kws={\"size\": 13})\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "#b += 0.5 # Add 0.5 to the bottom\n",
    "#t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.xlabel(\"PREDICTION\")\n",
    "plt.ylabel(\"TRUTH\")\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([41, 0], [43, 0], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_true, y_pred)\n",
    "print('AUC: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
